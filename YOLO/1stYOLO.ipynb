{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLOv8 basics\n",
    "\n",
    "### Hola Amigos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.227 ðŸš€ Python-3.11.6 torch-2.1.1 CPU (Apple M1)\n",
      "Setup complete âœ… (8 CPUs, 16.0 GB RAM, 755.9/926.4 GB disk)\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we installed the ultralytics package that contains the yolov8 module to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:03<00:00, 2.12MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/zeus/Repos/PyTorch_learning/YOLO/road.jpg: 384x640 41 cars, 1 bus, 4 trucks, 65.9ms\n",
      "Speed: 2.4ms preprocess, 65.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Results' object has no attribute 'show'. See valid attributes below.\n\n    A class for storing and manipulating inference results.\n\n    Args:\n        orig_img (numpy.ndarray): The original image as a numpy array.\n        path (str): The path to the image file.\n        names (dict): A dictionary of class names.\n        boxes (torch.tensor, optional): A 2D tensor of bounding box coordinates for each detection.\n        masks (torch.tensor, optional): A 3D tensor of detection masks, where each mask is a binary image.\n        probs (torch.tensor, optional): A 1D tensor of probabilities of each class for classification task.\n        keypoints (List[List[float]], optional): A list of detected keypoints for each object.\n\n    Attributes:\n        orig_img (numpy.ndarray): The original image as a numpy array.\n        orig_shape (tuple): The original image shape in (height, width) format.\n        boxes (Boxes, optional): A Boxes object containing the detection bounding boxes.\n        masks (Masks, optional): A Masks object containing the detection masks.\n        probs (Probs, optional): A Probs object containing probabilities of each class for classification task.\n        keypoints (Keypoints, optional): A Keypoints object containing detected keypoints for each object.\n        speed (dict): A dictionary of preprocess, inference, and postprocess speeds in milliseconds per image.\n        names (dict): A dictionary of class names.\n        path (str): The path to the image file.\n        _keys (tuple): A tuple of attribute names for non-empty attributes.\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m results \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./road.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m()\n",
      "File \u001b[0;32m~/miniforge3/envs/yayaEltarsh/lib/python3.11/site-packages/ultralytics/utils/__init__.py:153\u001b[0m, in \u001b[0;36mSimpleClass.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001b[39;00m\n\u001b[1;32m    152\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. See valid attributes below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Results' object has no attribute 'show'. See valid attributes below.\n\n    A class for storing and manipulating inference results.\n\n    Args:\n        orig_img (numpy.ndarray): The original image as a numpy array.\n        path (str): The path to the image file.\n        names (dict): A dictionary of class names.\n        boxes (torch.tensor, optional): A 2D tensor of bounding box coordinates for each detection.\n        masks (torch.tensor, optional): A 3D tensor of detection masks, where each mask is a binary image.\n        probs (torch.tensor, optional): A 1D tensor of probabilities of each class for classification task.\n        keypoints (List[List[float]], optional): A list of detected keypoints for each object.\n\n    Attributes:\n        orig_img (numpy.ndarray): The original image as a numpy array.\n        orig_shape (tuple): The original image shape in (height, width) format.\n        boxes (Boxes, optional): A Boxes object containing the detection bounding boxes.\n        masks (Masks, optional): A Masks object containing the detection masks.\n        probs (Probs, optional): A Probs object containing probabilities of each class for classification task.\n        keypoints (Keypoints, optional): A Keypoints object containing detected keypoints for each object.\n        speed (dict): A dictionary of preprocess, inference, and postprocess speeds in milliseconds per image.\n        names (dict): A dictionary of class names.\n        path (str): The path to the image file.\n        _keys (tuple): A tuple of attribute names for non-empty attributes.\n    "
     ]
    }
   ],
   "source": [
    "results = model('./road.jpg')\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yayaEltarsh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
